{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Create project_root for module imports\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Create data directory path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "save_dir = os.path.join(parent_dir, \"final_messages\", \"n_body_gravity\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Import relevant modules\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import random\n",
    "from gnn_model.graph_structure_from_trajecotry import node_data_list\n",
    "from gnn_model.message_passing_MLP import GNN_MLP\n",
    "from gnn_model.train_model import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_positions(N, dim, min_dist, box_size):\n",
    "    positions = []\n",
    "    while len(positions) < N:\n",
    "        pos = torch.rand(dim) * box_size\n",
    "        if all(torch.norm(pos - p) >= min_dist for p in positions):\n",
    "            positions.append(pos)\n",
    "    return torch.stack(positions)\n",
    "\n",
    "def generate_random_velocities(N, dim, velocity_scale=1.0):\n",
    "    return (torch.rand((N, dim)) - 0.5) * 2 * velocity_scale\n",
    "\n",
    "def compute_gravitational_forces(positions, masses, G=1.0, eps=1e-5):\n",
    "    N, dim = positions.shape\n",
    "    forces = torch.zeros_like(positions)\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            r_vec = positions[j] - positions[i]\n",
    "            dist = torch.norm(r_vec) + eps\n",
    "            force_mag = G * masses[i] * masses[j] / dist**2\n",
    "            force_dir = r_vec / dist\n",
    "            force = force_mag * force_dir\n",
    "            forces[i] += force\n",
    "            forces[j] -= force\n",
    "    return forces\n",
    "\n",
    "def generate_unique_masses(N, mass_range, resolution=25):\n",
    "\n",
    "    # Create a fine grid in the range\n",
    "    mass_grid = torch.linspace(mass_range[0], mass_range[1], resolution).tolist()\n",
    "    # Randomly choose N unique masses\n",
    "    unique_masses = random.sample(mass_grid, N)\n",
    "\n",
    "    return torch.tensor(unique_masses, dtype=torch.float32)\n",
    "\n",
    "def n_body_simulation(N=5, T=100, dt=0.01, dim=2,\n",
    "                      mass_range=(1.0, 30.0), min_dist=0.5,\n",
    "                      box_size=10.0, velocity_scale=1.0):\n",
    "    # Initialize\n",
    "    masses = generate_unique_masses(N, mass_range)\n",
    "    positions = generate_random_positions(N, dim, min_dist, box_size)\n",
    "    velocities = generate_random_velocities(N, dim, velocity_scale)\n",
    "\n",
    "    # Store results\n",
    "    trajectory = torch.zeros((T, N, dim), dtype=torch.float32)\n",
    "    trajectory_velocities = torch.zeros((T, N, dim), dtype=torch.float32)\n",
    "    t_array  = torch.arange(0, T * dt, dt, dtype=torch.float32)\n",
    "\n",
    "    for t in range(T):\n",
    "        trajectory[t] = positions\n",
    "        trajectory_velocities[t] = velocities\n",
    "\n",
    "        # Compute forces and update positions & velocities (Euler method)\n",
    "        forces = compute_gravitational_forces(positions, masses)\n",
    "        accelerations = forces / masses[:, None]\n",
    "        velocities = velocities + accelerations * dt\n",
    "        positions = positions + velocities * dt\n",
    "\n",
    "    trajectory_data = {\n",
    "        \"time\": t_array,\n",
    "        \"positions\": trajectory,\n",
    "        \"velocities\": trajectory_velocities,\n",
    "        \"masses\": masses\n",
    "    }\n",
    "\n",
    "    return trajectory_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def run_pipeline(iterations=10, train_fraction=0.7,\n",
    "                 N=5, T=100, dt=0.01, dim=2, hidden_channels=64,\n",
    "                 m_dim=2, out_channels=2, epochs=100, lr=0.001):\n",
    "\n",
    "    # 1) Run simulations\n",
    "    all_trajectories = [n_body_simulation(N=N, T=T, dt=dt, dim=dim) for _ in range(iterations)]\n",
    "\n",
    "    # 2) Convert to PyG data objects\n",
    "    all_graph_data = []\n",
    "    dataset_index = []\n",
    "    for idx, traj in enumerate(all_trajectories):\n",
    "        graphs = node_data_list(traj, self_loop=False, complete_graph=True)\n",
    "        all_graph_data.extend(graphs)\n",
    "        dataset_index.extend([idx] * len(graphs))\n",
    "\n",
    "    # 3) Split into train/test\n",
    "    indices = list(range(len(all_graph_data)))\n",
    "    train_idx, test_idx = train_test_split(indices, train_size=train_fraction, stratify=dataset_index)\n",
    "\n",
    "    train_data = [all_graph_data[i] for i in train_idx]\n",
    "    test_data = [all_graph_data[i] for i in test_idx]\n",
    "\n",
    "    # 4) Initialize the model\n",
    "    input_dim = train_data[0].x.shape[1]\n",
    "    model = GNN_MLP(n_f=input_dim, m_dim=m_dim, hidden_channels=hidden_channels,\n",
    "                    out_channels=out_channels, single_node=False)\n",
    "\n",
    "    # 5) Train model (save messages from final epoch)\n",
    "    model = train_model(model, train_data, epochs=epochs, lr=lr)\n",
    "\n",
    "    # 6) Extract training messages\n",
    "    train_messages = pd.DataFrame(model.message_storage)\n",
    "    train_messages[['pos_i_x', 'pos_i_y']] = pd.DataFrame(train_messages['pos_i'].tolist())\n",
    "    train_messages[['pos_j_x', 'pos_j_y']] = pd.DataFrame(train_messages['pos_j'].tolist())\n",
    "    train_messages[['message_x', 'message_y']] = pd.DataFrame(train_messages['message'].tolist())\n",
    "    train_messages = train_messages.drop(columns=['pos_i', 'pos_j', 'message', 'edge'])\n",
    "\n",
    "    # 7) Test on held-out data and store messages\n",
    "    model.message_storage = []  # Reset\n",
    "    for data in test_data:\n",
    "        _ = model(data.x, data.edge_index, save_messages=True)\n",
    "\n",
    "    test_messages = pd.DataFrame(model.message_storage)\n",
    "    test_messages[['pos_i_x', 'pos_i_y']] = pd.DataFrame(test_messages['pos_i'].tolist())\n",
    "    test_messages[['pos_j_x', 'pos_j_y']] = pd.DataFrame(test_messages['pos_j'].tolist())\n",
    "    test_messages[['message_x', 'message_y']] = pd.DataFrame(test_messages['message'].tolist())\n",
    "    test_messages = test_messages.drop(columns=['pos_i', 'pos_j', 'message', 'edge'])\n",
    "\n",
    "    return model, train_messages, test_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def run_pipeline_multi(iterations=10, train_fraction=0.7,\n",
    "                 N_train=2, N_test_list=[3, 4, 5, 6], T=100, dt=0.01, dim=2, hidden_channels=64,\n",
    "                 m_dim=2, out_channels=2, epochs=100, lr=0.001):\n",
    "\n",
    "    # 1) Run training simulations with N_train\n",
    "    train_trajectories = [n_body_simulation(N=N_train, T=T, dt=dt, dim=dim) for _ in range(int((train_fraction) *iterations))]\n",
    "\n",
    "    # 2) Convert training data to PyG objects\n",
    "    # all_train_graph_data = []\n",
    "    # train_dataset_index = []\n",
    "    # for idx, traj in enumerate(train_trajectories):\n",
    "    #     graphs = node_data_list(traj, self_loop=False, complete_graph=True)\n",
    "    #     all_train_graph_data.extend(graphs)\n",
    "    #     train_dataset_index.extend([idx] * len(graphs))\n",
    "\n",
    "    # # 3) Split training data\n",
    "    # train_indices, _ = train_test_split(\n",
    "    #     list(range(len(all_train_graph_data))),\n",
    "    #     train_size=train_fraction,\n",
    "    #     stratify=train_dataset_index\n",
    "    # )\n",
    "    \n",
    "    \n",
    "    train_graph_data = []\n",
    "    for traj in train_trajectories:\n",
    "        graphs = node_data_list(traj, self_loop=False, complete_graph=True)\n",
    "        train_graph_data.extend(graphs)\n",
    "    \n",
    "    # train_data = [all_train_graph_data[i] for i in train_indices]\n",
    "    train_data = [train_graph_data[i] for i in range(len(train_graph_data))]\n",
    "\n",
    "    # 4) Initialize model\n",
    "    input_dim = train_graph_data[0].x.shape[1]\n",
    "    model = GNN_MLP(n_f=input_dim, m_dim=m_dim, hidden_channels=hidden_channels,\n",
    "                    out_channels=out_channels, single_node=False)\n",
    "\n",
    "    # 5) Train model\n",
    "    model = train_model(model, train_data, epochs=epochs, lr=lr)\n",
    "\n",
    "    # 6) Extract training messages\n",
    "    train_messages = pd.DataFrame(model.message_storage)\n",
    "    train_messages[['pos_i_x', 'pos_i_y']] = pd.DataFrame(train_messages['pos_i'].tolist())\n",
    "    train_messages[['pos_j_x', 'pos_j_y']] = pd.DataFrame(train_messages['pos_j'].tolist())\n",
    "    train_messages[['message_x', 'message_y']] = pd.DataFrame(train_messages['message'].tolist())\n",
    "    train_messages = train_messages.drop(columns=['pos_i', 'pos_j', 'message', 'edge'])\n",
    "\n",
    "    # 7) Run and store test messages for each N in N_test_list\n",
    "    test_messages_all = {}\n",
    "    for N_test in N_test_list:\n",
    "        test_trajectories = [n_body_simulation(N=N_test, T=T, dt=dt, dim=dim) for _ in range(int((1-train_fraction)*iterations))]\n",
    "        test_graph_data = []\n",
    "        for traj in test_trajectories:\n",
    "            graphs = node_data_list(traj, self_loop=False, complete_graph=True)\n",
    "            test_graph_data.extend(graphs)\n",
    "\n",
    "        model.message_storage = []\n",
    "        for data in test_graph_data:\n",
    "            _ = model(data.x, data.edge_index, save_messages=True)\n",
    "\n",
    "        test_messages = pd.DataFrame(model.message_storage)\n",
    "        test_messages[['pos_i_x', 'pos_i_y']] = pd.DataFrame(test_messages['pos_i'].tolist())\n",
    "        test_messages[['pos_j_x', 'pos_j_y']] = pd.DataFrame(test_messages['pos_j'].tolist())\n",
    "        test_messages[['message_x', 'message_y']] = pd.DataFrame(test_messages['message'].tolist())\n",
    "        test_messages = test_messages.drop(columns=['pos_i', 'pos_j', 'message', 'edge'])\n",
    "\n",
    "        test_messages_all[N_test] = test_messages\n",
    "\n",
    "    return model, train_messages, test_messages_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/gnn_model/graph_structure_from_trajecotry.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n",
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/gnn_model/graph_structure_from_trajecotry.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n",
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/gnn_model/graph_structure_from_trajecotry.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n",
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/gnn_model/graph_structure_from_trajecotry.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n",
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/gnn_model/graph_structure_from_trajecotry.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n",
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/gnn_model/graph_structure_from_trajecotry.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "model_1, train_messages_1, test_messages_1 = run_pipeline_multi(iterations=10, train_fraction=0.7,\n",
    "                 N_train=2, N_test_list=[3, 4, 5, 6, 7], T=100, dt=0.01, dim=2, hidden_channels=128,\n",
    "                 m_dim=2, out_channels=2, epochs=100, lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_messages_1.to_csv(f\"{save_dir}/messages_cleaned.csv\", index=False)\n",
    "\n",
    "for i in range(3,8):\n",
    "    test_messages_1[i].to_csv(f\"{save_dir}/N_{i}_messages_test_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
