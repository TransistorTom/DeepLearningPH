{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/juliacall/__init__.py:61: UserWarning: torch was imported before juliacall. This may cause a segfault. To avoid this, import juliacall before importing torch. For updates, see https://github.com/pytorch/pytorch/issues/78829.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Create project_root for module imports\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Create data directory path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "save_dir = os.path.join(parent_dir, \"final_messages\", \"n_body_gravity\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Importing self-made models and functions\n",
    "from simulations.n_body_trajectory import n_body_simulation, generate_random_positions, generate_random_velocities, generate_unique_masses\n",
    "from gnn_model.node_data_list import node_data_list \n",
    "from gnn_model.GNN_MLP import GNN_MLP\n",
    "from gnn_model.train_model import train_model\n",
    "from gnn_model.pipeline import pipeline\n",
    "\n",
    "# Import other packages\n",
    "from pysr import PySRRegressor\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/DeepLearningPH/gnn_model/node_data_list.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: MSE = 5.791661, Mean Relative Error = 5.172515\n",
      "Epoch 002: MSE = 5.648638, Mean Relative Error = 6.640303\n",
      "Epoch 003: MSE = 5.515557, Mean Relative Error = 5.760372\n",
      "Epoch 004: MSE = 5.383263, Mean Relative Error = 5.495905\n",
      "Epoch 005: MSE = 5.299628, Mean Relative Error = 4.697012\n",
      "Epoch 006: MSE = 5.232416, Mean Relative Error = 4.632858\n",
      "Epoch 007: MSE = 5.128376, Mean Relative Error = 4.607641\n",
      "Epoch 008: MSE = 5.049407, Mean Relative Error = 5.227734\n",
      "Epoch 009: MSE = 4.971225, Mean Relative Error = 5.964803\n",
      "Epoch 010: MSE = 4.860635, Mean Relative Error = 5.686038\n",
      "Epoch 011: MSE = 4.746491, Mean Relative Error = 5.541693\n",
      "Epoch 012: MSE = 4.653703, Mean Relative Error = 5.063477\n",
      "Epoch 013: MSE = 4.527223, Mean Relative Error = 3.934885\n",
      "Epoch 014: MSE = 4.387501, Mean Relative Error = 3.822598\n",
      "Epoch 015: MSE = 4.235793, Mean Relative Error = 3.652461\n",
      "Epoch 016: MSE = 4.066146, Mean Relative Error = 3.418455\n",
      "Epoch 017: MSE = 3.924534, Mean Relative Error = 3.140674\n",
      "Epoch 018: MSE = 3.785672, Mean Relative Error = 2.724399\n",
      "Epoch 019: MSE = 3.655451, Mean Relative Error = 2.759825\n",
      "Epoch 020: MSE = 3.511446, Mean Relative Error = 2.697582\n",
      "Epoch 021: MSE = 3.372476, Mean Relative Error = 2.827795\n",
      "Epoch 022: MSE = 3.242480, Mean Relative Error = 2.721190\n",
      "Epoch 023: MSE = 3.164939, Mean Relative Error = 2.987809\n",
      "Epoch 024: MSE = 3.002971, Mean Relative Error = 3.522456\n",
      "Epoch 025: MSE = 2.937910, Mean Relative Error = 3.461026\n",
      "Epoch 026: MSE = 2.715719, Mean Relative Error = 3.874063\n",
      "Epoch 027: MSE = 2.567379, Mean Relative Error = 4.042394\n",
      "Epoch 028: MSE = 2.365419, Mean Relative Error = 4.130094\n",
      "Epoch 029: MSE = 2.215514, Mean Relative Error = 4.507006\n",
      "Epoch 030: MSE = 1.996190, Mean Relative Error = 3.961599\n",
      "Epoch 031: MSE = 2.140275, Mean Relative Error = 3.831822\n",
      "Epoch 032: MSE = 2.022589, Mean Relative Error = 3.124043\n",
      "Epoch 033: MSE = 1.808685, Mean Relative Error = 3.249943\n",
      "Epoch 034: MSE = 1.606355, Mean Relative Error = 4.134999\n",
      "Epoch 035: MSE = 1.706283, Mean Relative Error = 4.175727\n",
      "Epoch 036: MSE = 1.530188, Mean Relative Error = 3.694652\n",
      "Epoch 037: MSE = 1.197440, Mean Relative Error = 2.987382\n",
      "Epoch 038: MSE = 1.343363, Mean Relative Error = 2.217785\n",
      "Epoch 039: MSE = 1.141821, Mean Relative Error = 3.496318\n",
      "Epoch 040: MSE = 1.084435, Mean Relative Error = 2.803083\n",
      "Epoch 041: MSE = 0.985277, Mean Relative Error = 2.956995\n",
      "Epoch 042: MSE = 1.053531, Mean Relative Error = 2.332195\n",
      "Epoch 043: MSE = 0.918474, Mean Relative Error = 2.464603\n",
      "Epoch 044: MSE = 0.744651, Mean Relative Error = 1.888862\n",
      "Epoch 045: MSE = 0.761238, Mean Relative Error = 1.779243\n",
      "Epoch 046: MSE = 0.629456, Mean Relative Error = 2.599845\n",
      "Epoch 047: MSE = 0.552768, Mean Relative Error = 2.146135\n",
      "Epoch 048: MSE = 0.887832, Mean Relative Error = 2.445404\n",
      "Epoch 049: MSE = 0.549049, Mean Relative Error = 2.865823\n",
      "Epoch 050: MSE = 0.523585, Mean Relative Error = 3.319382\n",
      "Epoch 051: MSE = 1.922107, Mean Relative Error = 3.487344\n",
      "Epoch 052: MSE = 0.569948, Mean Relative Error = 2.983966\n",
      "Epoch 053: MSE = 1.404192, Mean Relative Error = 2.842948\n",
      "Epoch 054: MSE = 0.501570, Mean Relative Error = 2.981111\n",
      "Epoch 055: MSE = 1.169220, Mean Relative Error = 2.931878\n",
      "Epoch 056: MSE = 0.438447, Mean Relative Error = 2.658882\n",
      "Epoch 057: MSE = 0.931831, Mean Relative Error = 2.705375\n",
      "Epoch 058: MSE = 0.359937, Mean Relative Error = 2.480985\n",
      "Epoch 059: MSE = 0.519198, Mean Relative Error = 2.338620\n",
      "Epoch 060: MSE = 1.189919, Mean Relative Error = 2.995708\n",
      "Epoch 061: MSE = 1.076845, Mean Relative Error = 2.803208\n",
      "Epoch 062: MSE = 0.567179, Mean Relative Error = 2.184652\n",
      "Epoch 063: MSE = 1.320955, Mean Relative Error = 3.761345\n",
      "Epoch 064: MSE = 0.580859, Mean Relative Error = 2.550512\n",
      "Epoch 065: MSE = 0.947215, Mean Relative Error = 3.241768\n",
      "Epoch 066: MSE = 0.843266, Mean Relative Error = 2.757339\n",
      "Epoch 067: MSE = 0.575509, Mean Relative Error = 2.902314\n",
      "Epoch 068: MSE = 0.912125, Mean Relative Error = 2.624439\n",
      "Epoch 069: MSE = 0.859678, Mean Relative Error = 3.548308\n",
      "Epoch 070: MSE = 0.648724, Mean Relative Error = 2.133205\n",
      "Epoch 071: MSE = 1.314056, Mean Relative Error = 4.062083\n",
      "Epoch 072: MSE = 0.582245, Mean Relative Error = 2.614812\n",
      "Epoch 073: MSE = 1.019322, Mean Relative Error = 3.184146\n",
      "Epoch 074: MSE = 0.669555, Mean Relative Error = 2.661708\n",
      "Epoch 075: MSE = 0.376857, Mean Relative Error = 3.394091\n",
      "Epoch 076: MSE = 0.553151, Mean Relative Error = 2.970602\n",
      "Epoch 077: MSE = 0.922766, Mean Relative Error = 3.508655\n",
      "Epoch 078: MSE = 0.467604, Mean Relative Error = 2.579596\n",
      "Epoch 079: MSE = 0.396564, Mean Relative Error = 3.258369\n",
      "Epoch 080: MSE = 0.735574, Mean Relative Error = 2.760508\n",
      "Epoch 081: MSE = 0.923978, Mean Relative Error = 3.219965\n",
      "Epoch 082: MSE = 0.322537, Mean Relative Error = 2.594763\n",
      "Epoch 083: MSE = 0.734315, Mean Relative Error = 2.722225\n",
      "Epoch 084: MSE = 0.849991, Mean Relative Error = 3.979503\n",
      "Epoch 085: MSE = 0.626908, Mean Relative Error = 3.313012\n",
      "Epoch 086: MSE = 1.097671, Mean Relative Error = 4.190171\n",
      "Epoch 087: MSE = 0.578261, Mean Relative Error = 2.989465\n",
      "Epoch 088: MSE = 1.660639, Mean Relative Error = 2.935103\n",
      "Epoch 089: MSE = 0.284623, Mean Relative Error = 2.012725\n",
      "Epoch 090: MSE = 1.134219, Mean Relative Error = 3.129134\n",
      "Epoch 091: MSE = 0.542608, Mean Relative Error = 2.157683\n",
      "Epoch 092: MSE = 1.134823, Mean Relative Error = 2.713668\n",
      "Epoch 093: MSE = 0.510221, Mean Relative Error = 2.164583\n",
      "Epoch 094: MSE = 0.690512, Mean Relative Error = 2.784044\n",
      "Epoch 095: MSE = 0.596724, Mean Relative Error = 2.116490\n",
      "Epoch 096: MSE = 0.636967, Mean Relative Error = 2.753282\n",
      "Epoch 097: MSE = 1.218598, Mean Relative Error = 2.819644\n",
      "Epoch 098: MSE = 0.360609, Mean Relative Error = 2.468251\n",
      "Epoch 099: MSE = 0.753561, Mean Relative Error = 2.575707\n",
      "Epoch 100: MSE = 0.301361, Mean Relative Error = 1.754544\n"
     ]
    }
   ],
   "source": [
    "model_1, train_messages_1, test_messages_1 = pipeline(train_iterations=30, test_iterations=10,\n",
    "                 N_train=2, N_test_list=[2, 3, 4, 5, 6], T=200, dt=0.01, dim=2, hidden_channels=128,\n",
    "                 m_dim=2, out_channels=2, epochs=100, lr=0.0001, G=1.0, single_node=False, testing=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: MSE = 1.930786, Mean Relative Error = 2.343683\n",
      "Epoch 002: MSE = 1.930633, Mean Relative Error = 2.558603\n",
      "Epoch 003: MSE = 1.930634, Mean Relative Error = 2.582805\n",
      "Epoch 004: MSE = 1.930634, Mean Relative Error = 2.585809\n",
      "Epoch 005: MSE = 1.930634, Mean Relative Error = 2.586217\n",
      "Epoch 006: MSE = 1.930634, Mean Relative Error = 2.586273\n",
      "Epoch 007: MSE = 1.930634, Mean Relative Error = 2.586281\n",
      "Epoch 008: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 009: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 010: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 011: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 012: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 013: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 014: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 015: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 016: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 017: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 018: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 019: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 020: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 021: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 022: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 023: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 024: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 025: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 026: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 027: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 028: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 029: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 030: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 031: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 032: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 033: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 034: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 035: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 036: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 037: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 038: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 039: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 040: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 041: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 042: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 043: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 044: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 045: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 046: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 047: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 048: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 049: MSE = 1.930634, Mean Relative Error = 2.586282\n",
      "Epoch 050: MSE = 1.930634, Mean Relative Error = 2.586282\n"
     ]
    }
   ],
   "source": [
    "model_1, train_messages_1, test_messages_1 = pipeline(train_iterations=20, test_iterations=10,\n",
    "                 N_train=2, N_test_list=[2, 3, 4, 5, 6], T=100, dt=0.01, dim=2, hidden_channels=128,\n",
    "                 m_dim=2, out_channels=2, epochs=50, lr=0.001, G=1.0, single_node=False, testing=False, model=model_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_1.state_dict(), \"gnn_model_firstofmany.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = GNN_MLP(n_f=6, hidden_channels=128,\n",
    "                 m_dim=2, out_channels=2, single_node=False)\n",
    "model_loaded.load_state_dict(torch.load(\"gnn_model_firstofmany.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/DeepLearningPH/gnn_model/node_data_list.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "average loss per/over timestep N=2:   3.4190443477997876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/DeepLearningPH/gnn_model/node_data_list.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "average loss per/over timestep N=3:   47.750935309824314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/DeepLearningPH/gnn_model/node_data_list.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "average loss per/over timestep N=4:   215.99865845959596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/DeepLearningPH/gnn_model/node_data_list.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "average loss per/over timestep N=5:   620.8639942978367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobtoot/Documents/GitHub/DeepLearningPH/DeepLearningPH/gnn_model/node_data_list.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(acceleration, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "average loss per/over timestep N=6:   1038.892599641434\n"
     ]
    }
   ],
   "source": [
    "model_t, train_messages_t, test_messages_t = pipeline(train_iterations=20, test_iterations=10,\n",
    "                 N_train=2, N_test_list=[2, 3, 4, 5, 6], T=100, dt=0.01, dim=2, hidden_channels=128,\n",
    "                 m_dim=2, out_channels=2, epochs=50, lr=0.001, G=1.0, single_node=False, testing=True, training=False, model=model_loaded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_messages_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_messages_1\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/messages_single_node_false.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# for i in range(2,7):\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     test_messages_1[i].to_csv(f\"{save_dir}/N_{i}_messages_test_cleaned_presentation2.csv\", index=False)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_messages_1' is not defined"
     ]
    }
   ],
   "source": [
    "train_messages_1.to_csv(f\"{save_dir}/messages_single_node_false.csv\", index=False)\n",
    "\n",
    "# for i in range(2,7):\n",
    "#     test_messages_1[i].to_csv(f\"{save_dir}/N_{i}_messages_test_cleaned_presentation2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your cleaned DataFrame\n",
    "train_df = pd.read_csv(f\"{save_dir}/messages_single_node_false.csv\")\n",
    "\n",
    "train_df['dx'] = train_df['pos_j_x'] - train_df['pos_i_x']\n",
    "train_df['dy'] = train_df['pos_j_y'] - train_df['pos_i_y']\n",
    "train_df['r'] = np.sqrt(train_df['dx']**2 + train_df['dy']**2)\n",
    "train_df['r3'] = train_df['r']**3\n",
    "\n",
    "features = ['mass_j', 'dx', 'dy', 'r3']\n",
    "\n",
    "# train_df['force_x'] = train_df['message_x'] * train_df['mass_i']\n",
    "# train_df['force_y'] = train_df['message_y'] * train_df['mass_i']\n",
    "\n",
    "train_X = train_df[features].sample(frac=0.4, random_state=42)\n",
    "train_y_x = train_df['message_x'].sample(frac=0.4, random_state=42)\n",
    "train_y_y = train_df['message_y'].sample(frac=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features ['mass_j' 'dx' 'dy' 'r3']\n",
      "Compiling Julia backend...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expressions evaluated per second: 2.320e+05\n",
      "Head worker occupation: 17.5%\n",
      "Progress: 494 / 1500 total iterations (32.933%)\n",
      "====================================================================================================\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.847e+02  1.594e+01  y = 23.583\n",
      "3           7.146e+02  1.603e-01  y = 7.5662e-07 * r3\n",
      "5           3.198e+02  4.020e-01  y = (7.5662e-07 * r3) + 17.572\n",
      "7           1.447e+02  3.965e-01  y = (dx * (dx * 0.031598)) - -15.382\n",
      "9           9.926e+01  1.885e-01  y = 15.404 + ((dx - 13.377) * (0.031308 * dx))\n",
      "11          9.132e+01  4.166e-02  y = (((dy / mass_j) * (0.028878 * dx)) - -8.8786) + 8.4181\n",
      "13          8.638e+01  2.781e-02  y = 9.7676 + ((dx - (2.9376 - dy)) * (-0.9721 + (mass_j * 0.12...\n",
      "                                  669)))\n",
      "15          6.836e+01  1.170e-01  y = (9.7676 + 9.7676) + ((-0.9721 + (mass_j * 0.12669)) * (0.0...\n",
      "                                  96047 - (-0.9721 - dy)))\n",
      "17          4.530e+01  2.057e-01  y = ((11.655 - -1.8354) + 3.5836) + (((0.12667 * mass_j) + -0....\n",
      "                                  97052) * (dx - (-2.2937 - dy)))\n",
      "19          4.446e+01  9.345e-03  y = ((10.025 - 0.91772) + mass_j) + (((mass_j + dx) - (9.5873 ...\n",
      "                                  - dy)) * (-0.9721 + (mass_j * 0.12669)))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Expressions evaluated per second: 2.210e+05\n",
      "Head worker occupation: 19.0%\n",
      "Progress: 991 / 1500 total iterations (66.067%)\n",
      "====================================================================================================\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.847e+02  1.594e+01  y = 23.583\n",
      "3           5.370e+02  3.032e-01  y = 1.3062e-06 * r3\n",
      "5           2.211e+02  4.436e-01  y = (r3 * 1.1611e-06) + 18.117\n",
      "7           1.432e+02  2.173e-01  y = 17.187 + (dy * (dx * 0.0044724))\n",
      "9           5.304e+01  4.965e-01  y = (dy * (-1.1028 + (0.14409 * mass_j))) + 16.982\n",
      "11          4.576e+01  7.383e-02  y = 16.573 + ((dy + dx) * (-0.97216 + (mass_j * 0.12707)))\n",
      "13          4.474e+01  1.130e-02  y = (((0.12672 * mass_j) + -0.97212) * ((dy + dx) + mass_j)) +...\n",
      "                                   17.081\n",
      "15          4.449e+01  2.714e-03  y = 16.721 + (((0.12672 * mass_j) + -0.97212) * ((dy + -1.3514...\n",
      "                                  ) + (mass_j + dx)))\n",
      "17          4.446e+01  3.280e-04  y = (17.416 + -0.63538) + (((mass_j + dx) - (1.6939 - dy)) * (...\n",
      "                                  -0.9721 + (0.12669 * mass_j)))\n",
      "19          4.343e+01  1.176e-02  y = (((mass_j * 0.11352) + -0.876) * ((dy + dx) + 2.5947)) + (...\n",
      "                                  16.554 + (0.59607 - (-1.4077e-07 * r3)))\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "Best expression for message_x:\n",
      "PySRRegressor.equations_ = [\n",
      "\t   pick         score                                           equation  \\\n",
      "\t0        0.000000e+00                                          23.582973   \n",
      "\t1        3.031767e-01                                  1.3059548e-6 * r3   \n",
      "\t2        4.436420e-01                    (r3 * 1.1611216e-6) + 18.117336   \n",
      "\t3        2.173325e-01               17.18708 + (dy * (dx * 0.004472363))   \n",
      "\t4  >>>>  4.964919e-01  (dy * (-1.1027678 + (0.14409384 * mass_j))) + ...   \n",
      "\t5        7.383376e-02  16.573328 + ((dy + dx) * (-0.9721553 + (mass_j...   \n",
      "\t6        1.163255e-02  ((dy + (dx + mass_j)) * ((mass_j * 0.12630476)...   \n",
      "\t7        2.711959e-03  (((dy + -1.7015938) + (dx + mass_j)) * ((mass_...   \n",
      "\t8        8.996018e-08  (17.416155 + -0.63538355) + (((mass_j + dx) - ...   \n",
      "\t9        1.874345e-02  (((mass_j * 0.113518685) + -0.8759959) * ((dy ...   \n",
      "\t\n",
      "\t         loss  complexity  \n",
      "\t0  984.688540           1  \n",
      "\t1  536.985960           3  \n",
      "\t2  221.116120           5  \n",
      "\t3  143.168600           7  \n",
      "\t4   53.039620           9  \n",
      "\t5   45.758230          11  \n",
      "\t6   44.705948          13  \n",
      "\t7   44.464123          15  \n",
      "\t8   44.464115          17  \n",
      "\t9   42.828148          19  \n",
      "]\n",
      "Using features ['mass_j' 'dx' 'dy' 'r3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "[ Info: Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expressions evaluated per second: 2.710e+05\n",
      "Head worker occupation: 18.2%\n",
      "Progress: 508 / 1500 total iterations (33.867%)\n",
      "====================================================================================================\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           7.419e+01  1.594e+01  y = 5.5764\n",
      "3           3.500e+01  3.756e-01  y = r3 * 3.4555e-07\n",
      "5           1.879e+01  3.110e-01  y = 4.104 - (-3.1275e-07 * r3)\n",
      "7           1.444e+01  1.317e-01  y = (r3 * (2.0434e-06 / mass_j)) + 4.0986\n",
      "9           1.444e+01  4.768e-07  y = ((r3 + dx) * (2.0433e-06 / mass_j)) - -4.0987\n",
      "11          1.107e+01  1.330e-01  y = ((-0.28669 * dy) + ((dy * mass_j) * 0.038023)) + 3.8417\n",
      "15          1.065e+01  9.648e-03  y = (((-0.2867 * dy) - -3.5003) + ((mass_j * dy) * 0.038022)) ...\n",
      "                                  + (0.038022 * dx)\n",
      "17          8.703e+00  1.009e-01  y = (((dy * mass_j) * 0.037857) + ((dy * -0.31392) - (-0.20277...\n",
      "                                   * dx))) + (0.56352 / 0.13778)\n",
      "19          8.634e+00  3.971e-03  y = (((dy * mass_j) * 0.037857) + ((dy * -0.31392) - (-0.20277...\n",
      "                                   * dx))) + ((-0.53251 / -0.27615) - -1.8987)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Expressions evaluated per second: 2.610e+05\n",
      "Head worker occupation: 18.7%\n",
      "Progress: 1037 / 1500 total iterations (69.133%)\n",
      "====================================================================================================\n",
      "Hall of Fame:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           7.419e+01  1.594e+01  y = 5.5764\n",
      "3           3.500e+01  3.756e-01  y = r3 * 3.4555e-07\n",
      "5           1.879e+01  3.110e-01  y = 4.104 - (-3.1275e-07 * r3)\n",
      "7           1.408e+01  1.444e-01  y = ((0.0001702 * dy) * dy) + 3.8385\n",
      "9           1.063e+01  1.405e-01  y = ((dy * 0.0010977) * (dy / mass_j)) + 3.8456\n",
      "11          1.003e+01  2.887e-02  y = ((dy * 0.0010977) * ((dy / mass_j) + mass_j)) + 3.8456\n",
      "13          8.489e+00  8.355e-02  y = (((dy * 0.0010977) * (dy / mass_j)) + 3.8456) - (-0.096051...\n",
      "                                   * dx)\n",
      "15          8.142e+00  2.089e-02  y = ((dy * 0.0010977) * (dy / (mass_j + -0.5978))) + (3.8456 +...\n",
      "                                   (0.12443 * dx))\n",
      "17          7.942e+00  1.244e-02  y = (((dy * 0.0010977) / 1.0549) * (dy / (-0.66069 + mass_j)))...\n",
      "                                   + ((0.12443 * dx) + 3.8456)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "Best expression for message_y:\n",
      "PySRRegressor.equations_ = [\n",
      "\t   pick     score                                           equation  \\\n",
      "\t0        0.000000                                          5.5764265   \n",
      "\t1        0.375578                                  r3 * 3.4554978e-7   \n",
      "\t2        0.310985                   4.1039815 - (-3.1275042e-7 * r3)   \n",
      "\t3        0.144370            ((0.00017020355 * dy) * dy) + 3.8384874   \n",
      "\t4        0.147072  ((dx * 0.0077110077) * (dy / mass_j)) + 3.8978307   \n",
      "\t5        0.089827  ((dx * 0.0077110077) * ((dy / mass_j) + mass_j...   \n",
      "\t6        0.020365  ((dx * 0.0077110077) * ((dy / mass_j) + (3.897...   \n",
      "\t7        0.018184  ((0.001097662 * dy) * (dy / (mass_j + -0.50530...   \n",
      "\t8  >>>>  0.175212  ((0.18660349 * dx) - -3.8507304) + ((dy / (mas...   \n",
      "\t9        0.011479  (((0.18660349 / 0.8527837) * dx) - -3.8507304)...   \n",
      "\t\n",
      "\t        loss  complexity  \n",
      "\t0  74.186800           1  \n",
      "\t1  35.002910           3  \n",
      "\t2  18.792578           5  \n",
      "\t3  14.079540           7  \n",
      "\t4  10.491633           9  \n",
      "\t5   8.766376          11  \n",
      "\t6   8.416494          13  \n",
      "\t7   8.115899          15  \n",
      "\t8   5.716750          17  \n",
      "\t9   5.586996          19  \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create and fit SR model for message_x\n",
    "train_model_x = PySRRegressor(\n",
    "    niterations=100,\n",
    "    binary_operators=[\"+\", \"-\", \"*\", \"/\"],\n",
    "    # unary_operators=[\"cube\"],\n",
    "    model_selection=\"best\",  # Select best tradeoff between complexity and error\n",
    "    select_k_features=5,  # small number of features\n",
    "    verbosity=1,\n",
    "    maxdepth=5,\n",
    ")\n",
    "\n",
    "train_model_x.fit(train_X.values, train_y_x.values, variable_names = features)\n",
    "\n",
    "# Print best expression for message_x\n",
    "print(\"Best expression for message_x:\")\n",
    "print(train_model_x)\n",
    "\n",
    "# Optionally: model for message_y too\n",
    "train_model_y = PySRRegressor(\n",
    "    niterations=100,\n",
    "    binary_operators=[\"+\", \"-\", \"*\", \"/\"],\n",
    "    # unary_operators=[\"cube\"],\n",
    "    model_selection=\"best\",\n",
    "    select_k_features=5,  # small number of features\n",
    "    verbosity=1,\n",
    "    maxdepth=5,\n",
    ")\n",
    "\n",
    "train_model_y.fit(train_X.values, train_y_y.values, variable_names = features)\n",
    "print(\"Best expression for message_y:\")\n",
    "print(train_model_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complexity                                                       9\n",
      "loss                                                      53.03962\n",
      "score                                                     0.493036\n",
      "equation         ((0.14408699 * dy) * (mass_j - 7.653176)) - -1...\n",
      "sympy_format     0.14408699*dy*(mass_j - 1*7.653176) - 1*(-16.9...\n",
      "lambda_format    PySRFunction(X=>0.14408699*dy*(mass_j - 1*7.65...\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "# Assume you have already trained a PySR model\n",
    "train_model_x.refresh()  # Load results if not already loaded\n",
    "\n",
    "# Extract discovered equations\n",
    "df = train_model_x.equations_\n",
    "df = df.sort_values(\"complexity\")  # Ensure sorting by complexity\n",
    "\n",
    "# Compute the selection criterion\n",
    "complexities = df[\"complexity\"].values\n",
    "mse_values = df[\"loss\"].values  # Loss is usually MSE in PySR\n",
    "\n",
    "# Compute fractional drop in log MSE\n",
    "delta_log_mse = -np.diff(np.log(mse_values))\n",
    "delta_complexity = np.diff(complexities)\n",
    "\n",
    "# Compute selection criterion\n",
    "selection_criterion = delta_log_mse / delta_complexity\n",
    "\n",
    "# Find the best model according to the criterion\n",
    "best_index = np.argmax(selection_criterion)\n",
    "best_model = df.iloc[best_index + 1]  # +1 because diff reduces size by 1\n",
    "\n",
    "# Display best model\n",
    "print(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.14408699 * dy) * (mass_j - 7.653176)) - -16.981506\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[4, 'equation'])\n",
    "# print(df.loc[4, 'sympy_format'])\n",
    "# print(df.loc[4, 'lambda_format'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
